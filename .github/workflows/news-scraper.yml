name: News Scraper

on:
  workflow_dispatch:  # Manual trigger only
  schedule:
    - cron: "0 */6 * * *"  # Every 6 hours (reduced frequency)

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4
      
      - name: Run news scraper
        run: python scripts/scrape_news.py
      
      - name: Display results
        run: |
          echo "News scraping completed"
          if [ -f market.json ]; then
            echo "Market data updated successfully"
            head -10 market.json
          else
            echo "Market data file not found"
          fi
      
      - name: Check for changes
        id: verify-changed-files
        run: |
          if [ -f market.json ]; then
            echo "changed=true" >> $GITHUB_OUTPUT
          else
            echo "changed=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Commit and push changes
        if: steps.verify-changed-files.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add market.json
          git commit -m "Update market sentiment data [$(date +'%Y-%m-%d %H:%M:%S')]" || echo "No changes to commit"
          git push